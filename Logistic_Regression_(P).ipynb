{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Logistic Regression***"
      ],
      "metadata": {
        "id": "MHKPuzQGOOa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 . Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic\n",
        "Regression, and prints the model accuracy ?"
      ],
      "metadata": {
        "id": "X4HlvqDjOSaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Logistic Regression Model Accuracy:\", round(accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_PtCz3jOSB7",
        "outputId": "e975b866-b420-4b4f-b99f-9044bfab72d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Accuracy: 100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 .  Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1')\n",
        "and print the model accuracy ?"
      ],
      "metadata": {
        "id": "w1uPam_5Ovhh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "724Up7FlOAfH",
        "outputId": "7e2fbccc-5c08-4130-eb4c-13f9bfcc6edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with L1 Regularization Accuracy: 100.0 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "import numpy as np\n",
        "y_binary = np.where(y == 0, 0, 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Logistic Regression with L1 Regularization Accuracy:\", round(accuracy * 100, 2), \"%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 . Write a Python program to train Logistic Regression with L2 regularization (Ridge) using\n",
        "LogisticRegression(penalty='l2'). Print model accuracy and coefficients ?"
      ],
      "metadata": {
        "id": "p5NC3jIXPGUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', multi_class='multinomial', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Logistic Regression with L2 Regularization Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
        "print(\"\\nModel Coefficients (one row per class):\")\n",
        "print(model.coef_)\n",
        "print(\"\\nIntercepts for each class:\")\n",
        "print(model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN7F7hQ-POy4",
        "outputId": "542c168f-89dc-4c3f-9982-5c7ac1f2bf4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with L2 Regularization Accuracy: 100.0 %\n",
            "\n",
            "Model Coefficients (one row per class):\n",
            "[[-0.39345607  0.96251768 -2.37512436 -0.99874594]\n",
            " [ 0.50843279 -0.25482714 -0.21301129 -0.77574766]\n",
            " [-0.11497673 -0.70769055  2.58813565  1.7744936 ]]\n",
            "\n",
            "Intercepts for each class:\n",
            "[  9.00884295   1.86902164 -10.87786459]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 .  Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')?"
      ],
      "metadata": {
        "id": "5_gp6QlZPgOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',\n",
        "    l1_ratio=0.5,           # Mix of L1 and L2\n",
        "    multi_class='multinomial',\n",
        "    max_iter=500\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Elastic Net Logistic Regression Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(model.coef_)\n",
        "print(\"\\nIntercepts:\")\n",
        "print(model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_C411qwP-Xw",
        "outputId": "ad7e48b0-4b19-4b31-da13-b8c3501e3077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Logistic Regression Accuracy: 100.0 %\n",
            "\n",
            "Model Coefficients:\n",
            "[[ 0.25554091  1.73433195 -2.4313729  -0.61899734]\n",
            " [ 0.          0.          0.         -0.50797239]\n",
            " [-1.01130976 -1.209893    2.64696202  2.10759311]]\n",
            "\n",
            "Intercepts:\n",
            "[ 2.53943448  2.4814638  -5.02089828]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 . Write a Python program to train a Logistic Regression model for multiclass classification using\n",
        "multi_class='ovr'?\n"
      ],
      "metadata": {
        "id": "CyRioHsiPqFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Multiclass Logistic Regression (One-vs-Rest) Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(model.coef_)\n",
        "print(\"\\nIntercepts:\")\n",
        "print(model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn-u-3PaQIc6",
        "outputId": "304be5ea-5624-4198-c200-309fa27d7f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Regression (One-vs-Rest) Accuracy: 100.0 %\n",
            "\n",
            "Model Coefficients:\n",
            "[[ 0.3711229   1.409712   -2.15210117 -0.95474179]\n",
            " [ 0.49400451 -1.58897112  0.43717015 -1.11187838]\n",
            " [-1.55895271 -1.58893375  2.39874554  2.15556209]]\n",
            "\n",
            "Intercepts:\n",
            "[ 0.2478905   0.86408083 -1.00411267]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 . Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic\n",
        "Regression. Print the best parameters and accuracy ?"
      ],
      "metadata": {
        "id": "U6STMoJPQX5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=200)\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Test Set Accuracy with Best Model:\", round(accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pfvhexDQmZ8",
        "outputId": "fbbcd941-ea2a-46d3-f92c-dd07aab01e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Test Set Accuracy with Best Model: 100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 . Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the\n",
        "average accuracy ?"
      ],
      "metadata": {
        "id": "9eSMnd2nSeIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200, solver='liblinear', multi_class='ovr')\n",
        "\n",
        "accuracies = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "print(\"Accuracy for each fold:\", np.round(accuracies, 4))\n",
        "print(\"Average Accuracy:\", round(np.mean(accuracies) * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muKruTazSi3b",
        "outputId": "c90fe6f1-fdab-499a-d18e-09db033795da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each fold: [0.9667 1.     0.9    0.9333 1.    ]\n",
            "Average Accuracy: 96.0 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8 . Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its\n",
        "accuracy ?"
      ],
      "metadata": {
        "id": "8NRXgabRSwmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv('your_file.csv')\n",
        "\n",
        "X = df.drop('target_column', axis=1)\n",
        "y = df['target_column']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Logistic Regression Model Accuracy:\", round(accuracy * 100, 2), \"%\")"
      ],
      "metadata": {
        "id": "jV4jPT-8TTjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9 . Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in\n",
        "Logistic Regression. Print the best parameters and accuracy"
      ],
      "metadata": {
        "id": "c-qSjBlrTVBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'C': np.logspace(-3, 2, 10),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [200, 300, 500]\n",
        "}\n",
        "\n",
        "log_reg = LogisticRegression(multi_class='ovr')\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=log_reg,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    random_state=42\n",
        ")\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"Test Set Accuracy:\", round(accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMfTf1DTTott",
        "outputId": "fe48fa54-f080-4355-d5a2-2bad3e8c9d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'solver': 'saga', 'penalty': 'l2', 'max_iter': 500, 'C': np.float64(27.825594022071257)}\n",
            "Test Set Accuracy: 100.0 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 . Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy?"
      ],
      "metadata": {
        "id": "mWrb9kaOTgle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "base_model = LogisticRegression(solver='liblinear', max_iter=200)\n",
        "ovo_model = OneVsOneClassifier(base_model)\n",
        "\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"One-vs-One (OvO) Logistic Regression Accuracy:\", round(accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY3ht1cSVxdy",
        "outputId": "b30382c4-b8e0-4e61-c884-bcc9b9d49460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One (OvO) Logistic Regression Accuracy: 100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11 . Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary\n",
        "classification ?"
      ],
      "metadata": {
        "id": "bTa9sFCDV87j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", round(acc * 100, 2), \"%\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Logistic Regression')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "xlPNljanWDID",
        "outputId": "6515e027-d01e-4c13-856d-987d33c446cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.61 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12 . Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
        "Recall, and F1-Score ?"
      ],
      "metadata": {
        "id": "18jYLrt6XIw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Precision:\", round(precision, 2))\n",
        "print(\"Recall:\", round(recall, 2))\n",
        "print(\"F1-Score:\", round(f1, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHr5ycNkXO1F",
        "outputId": "ef9d371b-50b7-41a6-e1c1-34ee47624158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.95\n",
            "Recall: 0.99\n",
            "F1-Score: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13 . Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to\n",
        "improve model performance?"
      ],
      "metadata": {
        "id": "zyN4zm9mXyOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=10,\n",
        "    n_informative=5,\n",
        "    n_redundant=2,\n",
        "    n_classes=2,\n",
        "    weights=[0.9, 0.1],\n",
        "    flip_y=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report with Balanced Class Weights:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXfYSGxyX6-I",
        "outputId": "59488744-1622-435f-844f-93a7f85b46b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report with Balanced Class Weights:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.83      0.90       180\n",
            "           1       0.35      0.85      0.50        20\n",
            "\n",
            "    accuracy                           0.83       200\n",
            "   macro avg       0.67      0.84      0.70       200\n",
            "weighted avg       0.92      0.83      0.86       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14 . Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and\n",
        "evaluate performance ?"
      ],
      "metadata": {
        "id": "4axHWWVGop9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "le_sex = LabelEncoder()\n",
        "le_embarked = LabelEncoder()\n",
        "df['Sex'] = le_sex.fit_transform(df['Sex'])         # male = 1, female = 0\n",
        "df['Embarked'] = le_embarked.fit_transform(df['Embarked'])\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzNlBa1ior65",
        "outputId": "edb1349c-c224-4c54-ba2e-b9e30a5c8652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       105\n",
            "           1       0.79      0.74      0.76        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.81      0.80      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-e7d88d11f30b>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
            "<ipython-input-14-e7d88d11f30b>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 .  Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression\n",
        "model. Evaluate its accuracy and compare results with and without scaling ?"
      ],
      "metadata": {
        "id": "aLpgHhSmpBY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_no_scaling = LogisticRegression(max_iter=500)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "acc_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=500)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(\"Accuracy WITHOUT Scaling:\", round(acc_no_scaling * 100, 2), \"%\")\n",
        "print(\"Accuracy WITH Scaling   :\", round(acc_scaled * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUwwUAX0pSqI",
        "outputId": "c120f003-5747-447f-e157-affa021d76ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy WITHOUT Scaling: 95.61 %\n",
            "Accuracy WITH Scaling   : 97.37 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16 .  Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score ?"
      ],
      "metadata": {
        "id": "lKik2OeepkH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_probs = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(\"ROC-AUC Score:\", round(roc_auc, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CPNpWULptiX",
        "outputId": "fb045073-1c72-4c95-e8bd-51a0405ccdad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17 .  Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate\n",
        "accuracy ?"
      ],
      "metadata": {
        "id": "Zmqjz28np-rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(C=0.5, max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Logistic Regression Accuracy with C=0.5:\", round(accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-83UUJUJqEB9",
        "outputId": "2f1e157f-e36a-4d85-caef-30e8d1e8ff69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy with C=0.5: 95.61 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18 .  Write a Python program to train Logistic Regression and identify important features based on model\n",
        "coefficients ?"
      ],
      "metadata": {
        "id": "uGfA67ysqTlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "coefficients = model.coef_[0]\n",
        "feature_importance = pd.Series(coefficients, index=X.columns)\n",
        "\n",
        "important_features = feature_importance.abs().sort_values(ascending=False)\n",
        "\n",
        "print(\"Top 10 Important Features based on Coefficients:\")\n",
        "print(important_features.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEBb1tdtqZdw",
        "outputId": "4ea2a2e3-b39f-47d4-b9e1-97bd06b3cf41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Important Features based on Coefficients:\n",
            "mean radius             2.089271\n",
            "worst concavity         1.599262\n",
            "texture error           1.480208\n",
            "worst radius            1.274299\n",
            "worst compactness       1.225435\n",
            "worst symmetry          0.708840\n",
            "mean concavity          0.630984\n",
            "worst concave points    0.586922\n",
            "mean compactness        0.413271\n",
            "worst texture           0.405904\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19 . Write a Python program to train Logistic Regression and evaluate its performance using Cohens Kappa\n",
        "Score ?"
      ],
      "metadata": {
        "id": "DAI0XkR2qqUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(\"Cohens Kappa Score:\", round(kappa, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67q204QrqzXw",
        "outputId": "2cd99ea4-feab-4af2-c38b-36fc191cd161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohens Kappa Score: 0.9053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20 . Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary\n",
        "classification ?"
      ],
      "metadata": {
        "id": "-2VXZcJ_rA1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "average_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(recall, precision, label=f'AP = {average_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve - Logistic Regression')\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "_BWFOOIBrI8k",
        "outputId": "59fa903f-086c-4384-84b3-f47ce6486042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21 .  Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare\n",
        "their accuracy ?"
      ],
      "metadata": {
        "id": "UhSY-7GPrdiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "results = {}\n",
        "\n",
        "for solver in solvers:\n",
        "    try:\n",
        "        model = LogisticRegression(solver=solver, max_iter=500)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results[solver] = round(accuracy * 100, 2)\n",
        "    except Exception as e:\n",
        "        results[solver] = f\"Error: {str(e)}\"\n",
        "\n",
        "print(\"Solver Accuracy Comparison (Breast Cancer Dataset):\")\n",
        "for solver, acc in results.items():\n",
        "    print(f\"  {solver}: {acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBHYwqgRrjVS",
        "outputId": "469add73-7c2e-4aee-dcb4-e5da82460618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver Accuracy Comparison (Breast Cancer Dataset):\n",
            "  liblinear: 95.61\n",
            "  saga: 95.61\n",
            "  lbfgs: 95.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22 . Write a Python program to train Logistic Regression and evaluate its performance using Matthews\n",
        "Correlation Coefficient (MCC) ?"
      ],
      "metadata": {
        "id": "UC34q9BUruYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target  # Binary: 0 = malignant, 1 = benign\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", round(mcc, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQGrO54KrzrC",
        "outputId": "68fda715-6455-4e8c-dc52-e6ac8ca16d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.9068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23 . Write a Python program to train Logistic Regression on both raw and standardized data. Compare their\n",
        "accuracy to see the impact of feature scaling ?"
      ],
      "metadata": {
        "id": "8xuBJ7xfsB4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_raw = LogisticRegression(max_iter=500)\n",
        "model_raw.fit(X_train_raw, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test_raw)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_raw)\n",
        "X_test_scaled = scaler.transform(X_test_raw)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=500)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(\"Accuracy WITHOUT Scaling:\", round(accuracy_raw * 100, 2), \"%\")\n",
        "print(\"Accuracy WITH Scaling   :\", round(accuracy_scaled * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFtcK8qGsGYC",
        "outputId": "33342c4c-14ad-446a-c7f6-cf09b0c54850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy WITHOUT Scaling: 95.61 %\n",
            "Accuracy WITH Scaling   : 97.37 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24 . Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using\n",
        "cross-validation ?"
      ],
      "metadata": {
        "id": "L3D57V-asWt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': np.logspace(-3, 2, 10)  # e.g., [0.001, 0.01, ..., 100]\n",
        "}\n",
        "\n",
        "model = LogisticRegression(max_iter=500, solver='liblinear')\n",
        "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_C = grid.best_params_['C']\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Regularization Strength (C):\", best_C)\n",
        "print(\"Test Accuracy with Best C:\", round(test_accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkQkeSCMscl2",
        "outputId": "9a1599c4-a870-4224-99b5-b8dac37ae11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Regularization Strength (C): 27.825594022071257\n",
            "Test Accuracy with Best C: 95.61 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25 . Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
        "make predictions ?"
      ],
      "metadata": {
        "id": "Lv6-xpa4s0wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(model, 'logistic_model.pkl')\n",
        "\n",
        "loaded_model = joblib.load('logistic_model.pkl')\n",
        "\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Loaded Model:\", round(accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt94PHVzs5sZ",
        "outputId": "027206b1-5a8d-408b-98c1-d1a1661cc29a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Loaded Model: 95.61 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}